from sentence_transformers import SentenceTransformer
import torch

# Download from the ü§ó Hub
model = SentenceTransformer("hiieu/halong_embedding")

# Define query and documents
query = "B√≥ng b√†n c√≥ l·ª£i √≠ch g√¨ cho s·ª©c kh·ªèe?"
docs = [
    "B√≥ng ƒë√° gi√∫p c·∫£i thi·ªán s·ª©c kh·ªèe tim m·∫°ch v√† tƒÉng c∆∞·ªùng s·ª©c b·ªÅn.",
    "B√≥ng ƒë√° l√† m√¥n th·ªÉ thao ph·ªï bi·∫øn nh·∫•t th·∫ø gi·ªõi.",
    "Ch∆°i b√≥ng ƒë√° gi√∫p gi·∫£m cƒÉng th·∫≥ng v√† c·∫£i thi·ªán t√¢m l√Ω.",
    "B√≥ng ƒë√° c√≥ th·ªÉ gi√∫p b·∫°n k·∫øt n·ªëi v·ªõi nhi·ªÅu ng∆∞·ªùi h∆°n.",
    "B√≥ng ƒë√° kh√¥ng ch·ªâ l√† m√¥n th·ªÉ thao m√† c√≤n l√† c√°ch ƒë·ªÉ gi·∫£i tr√≠.",
    "Ngo√†i b√≥ng ƒë√° ra, c√≤n nhi·ªÅu m√¥n th·ªÉ thao kh√°c c≈©ng gi√∫p c·∫£i thi·ªán s·ª©c kh·ªèe."
]

# Encode query and documents
query_embedding = model.encode([query])
doc_embeddings = model.encode(docs)
similarities = model.similarity(query_embedding, doc_embeddings).flatten()

# Sort documents by cosine similarity
sorted_indices = torch.argsort(similarities, descending=True)
sorted_docs = [docs[idx] for idx in sorted_indices]
sorted_scores = [similarities[idx].item() for idx in sorted_indices]

# Print sorted documents with their cosine scores
for doc, score in zip(sorted_docs, sorted_scores):
    print(f"Document: {doc} - Cosine Similarity: {score:.4f}")

# Document: B√≥ng ƒë√° gi√∫p c·∫£i thi·ªán s·ª©c kh·ªèe tim m·∫°ch v√† tƒÉng c∆∞·ªùng s·ª©c b·ªÅn. - Cosine Similarity: 0.7318
# Document: Ch∆°i b√≥ng ƒë√° gi√∫p gi·∫£m cƒÉng th·∫≥ng v√† c·∫£i thi·ªán t√¢m l√Ω. - Cosine Similarity: 0.6623
# Document: B√≥ng ƒë√° kh√¥ng ch·ªâ l√† m√¥n th·ªÉ thao m√† c√≤n l√† c√°ch ƒë·ªÉ gi·∫£i tr√≠. - Cosine Similarity: 0.6102
# Document: B√≥ng ƒë√° c√≥ th·ªÉ gi√∫p b·∫°n k·∫øt n·ªëi v·ªõi nhi·ªÅu ng∆∞·ªùi h∆°n. - Cosine Similarity: 0.4988
# Document: B√≥ng ƒë√° l√† m√¥n th·ªÉ thao ph·ªï bi·∫øn nh·∫•t th·∫ø gi·ªõi. - Cosine Similarity: 0.4828
